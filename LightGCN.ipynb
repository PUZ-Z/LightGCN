{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GCN ë…¼ë¬¸ ë¦¬ë·° & ì½”ë“œ ì‘ì„±\n",
    "**LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation**  \n",
    "*He et al. (2020)*  \n",
    "ğŸ”— [ë…¼ë¬¸ ë§í¬](https://arxiv.org/abs/2002.02126)\n",
    "\n",
    "---\n",
    "\n",
    "## í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "ìœ ì €ì™€ ì•„ì´í…œì˜ ì´ˆê¸° ì„ë² ë”©ì„ ê°ê° $e_u^{(0)}, e_i^{(0)}$ ë¼ê³  í•  ë•Œ, kë²ˆì§¸ layerì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì—…ë°ì´íŠ¸ ëœë‹¤.\n",
    "\n",
    "$$\n",
    "e_u^{(k+1)} = \\sum_{i\\in{N_n}}\\frac{1}{\\sqrt{|N_u||N_i|}}e_i^{(k)}\n",
    "$$\n",
    "\n",
    "ë§ˆì§€ë§‰ì—ëŠ” ì—¬ëŸ¬ ë ˆì´ì–´ì˜ ì„ë² ë”©ì„ í‰ê·  or ê°€ì¤‘í•© í•´ì„œ ìµœì¢… ì„ë² ë”©ì„ ë§Œë“ ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from collections import defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì„¤ì • (Hyperparameter)\n",
    "\n",
    "|í•­ëª©|ì„¤ì •|\n",
    "|:---:|:---:|\n",
    "|ì„ë² ë”© ì°¨ì›|64|\n",
    "|í•™ìŠµë¥ |0.001|\n",
    "|optimizer|Adam|\n",
    "|weight decay|1e-4(ì •ê·œí™” í•­ìœ¼ë¡œ BPRì— í¬í•¨)|\n",
    "|negative sampling|1:1 ë¹„ìœ¨ë¡œ sampling|\n",
    "|ë°°ì¹˜  ì‚¬ì´ì¦ˆ|1024(Amazon Books : 2048)|\n",
    "|í•™ìŠµ epoch|max 1000, ì¼ë°˜ì ìœ¼ë¡œ 200~400|\n",
    "|ë ˆì´ì–´ ìˆ˜|3|\n",
    "|ì´ˆê¸°í™”|Xavier uniform|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'embedding_dim': 64,\n",
    "    'num_layers': 3,\n",
    "    'lr': 0.001,\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 200,\n",
    "    'patience': 10,\n",
    "    'eval_k': 20,\n",
    "    'reg_lambda': 1e-4,\n",
    "    'debug': False,\n",
    "    'dropout': False,\n",
    "    'keep_prob': 0.6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\"))\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Users: 52643, # Interactions: 2380730, # Items: 91599\n"
     ]
    }
   ],
   "source": [
    "# train.txt ë¡œë“œ â†’ user_item_dict\n",
    "user_item_dict = defaultdict(set)\n",
    "with open(\"data/train.txt\") as f:\n",
    "    for user, line in enumerate(f):\n",
    "        items = list(map(int, line.strip().split()))\n",
    "        for item in items[1:]:\n",
    "            user_item_dict[user].add(item)\n",
    "\n",
    "# test.txt ë¡œë“œ â†’ test_ground_truth\n",
    "test_ground_truth = {}\n",
    "\n",
    "with open(\"data/test.txt\") as f:\n",
    "    for user, line in enumerate(f):\n",
    "        parts = list(map(int, line.strip().split()))\n",
    "        if len(parts) < 2:\n",
    "            continue  # ìœ ì € IDë§Œ ìˆëŠ” ê²½ìš°ëŠ” ê±´ë„ˆë›°ê¸°\n",
    "        items = parts[1:]  # ìœ ì € ID ë’¤ì— ë‚˜ì˜¤ëŠ” ëª¨ë“  ì•„ì´í…œ\n",
    "        test_ground_truth[user] = items\n",
    "\n",
    "\n",
    "# train_interactions ìƒì„± (for model input)\n",
    "train_user, train_item = [], []\n",
    "for user, items in user_item_dict.items():\n",
    "    for item in items:\n",
    "        train_user.append(user)\n",
    "        train_item.append(item)\n",
    "\n",
    "train_interactions = torch.stack([\n",
    "    torch.tensor(train_user),\n",
    "    torch.tensor(train_item)\n",
    "], dim=0)\n",
    "\n",
    "# ì‚¬ìš©ì-ì•„ì´í…œ ë”•ì…”ë„ˆë¦¬ë¡œë¶€í„° ìœ ì €/ì•„ì´í…œ ìˆ˜ ê³„ì‚°\n",
    "all_items = set()\n",
    "for items in user_item_dict.values():\n",
    "    all_items.update(items)\n",
    "for items in test_ground_truth.values():\n",
    "    all_items.update(items)\n",
    "num_items = max(all_items) + 1\n",
    "num_users = len(user_item_dict)\n",
    "\n",
    "# í†µê³„ í™•ì¸\n",
    "print(f\"# Users: {num_users}, # Interactions: {len(train_user)}, # Items: {num_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGCN ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    # ëª¨ë¸ì´ ì‚¬ìš©í•  ìœ ì €/ì•„ì´í…œ ìˆ˜, ì„ë² ë”© ì°¨ì›, GCN ë ˆì´ì–´ ìˆ˜, ì—£ì§€ êµ¬ì¡°ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ë¶€ë¶„\n",
    "    def __init__(self, num_users, num_items, embedding_dim, num_layers, user_item_pairs):\n",
    "        super(LightGCN, self).__init__()\n",
    "        \n",
    "        # í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # ìœ ì €, ì•„ì´í…œ ê°ê°ì— ëŒ€í•œ í•™ìŠµ ê°€ëŠ¥í•œ ì„ë² ë”© ë²¡í„° ì •ì˜\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # ì„ë² ë”© ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”(ë…¼ë¬¸ì—ì„œ Xavier ì´ˆê¸°í™” ì‚¬ìš©)\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "\n",
    "        # ì—£ì§€ êµ¬ì¡° ì €ì¥\n",
    "        self.norm_adj = self.build_adj_matrix(user_item_pairs)\n",
    "\n",
    "    # ìœ ì €-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ê·œí™”ëœ ì¸ì ‘ í–‰ë ¬ì„ ë§Œë“¤ê¸° ìœ„í•¨\n",
    "    def build_adj_matrix(self, user_item_pairs):\n",
    "        num_nodes = self.num_users + self.num_items # ë…¸ë“œ ê°œìˆ˜ ì„¤ì •\n",
    "        \n",
    "        # bipartite graph ë§Œë“¤ê¸°\n",
    "        rows = user_item_pairs[0].cpu().numpy()\n",
    "        cols = user_item_pairs[1].cpu().numpy() + self.num_users\n",
    "        \n",
    "        R = coo_matrix((np.ones(len(rows)), (rows, cols)), shape=(num_nodes, num_nodes)) # ì—£ì§€ ê°€ì¤‘ì¹˜ë¥¼ ì „ë¶€ 1.0ìœ¼ë¡œ ì„¤ì •ë˜ê³  ìˆìŒ\n",
    "        \n",
    "        # ì–‘ë°©í–¥ìœ¼ë¡œ ì—°ê²°(symmetric adjacency)\n",
    "        adj = R + R.T\n",
    "\n",
    "        # ì •ê·œí™”\n",
    "        rowsum = np.array(adj.sum(1)).flatten() # degree ê³„ì‚°\n",
    "        d_inv_sqrt = np.power(rowsum + 1e-8, -0.5) # degree matrix D ê³„ì‚° -> ì—­ë£¨íŠ¸ ì·¨í•´ì„œ ì •ê·œí™”ì— ì‚¬ìš©\n",
    "        d_mat_inv_sqrt = coo_matrix((d_inv_sqrt, (np.arange(num_nodes), np.arange(num_nodes))), shape=(num_nodes, num_nodes))\n",
    "\n",
    "        norm_adj = d_mat_inv_sqrt @ adj @ d_mat_inv_sqrt # ì •ê·œí™”ëœ sparse adjacency matrix\n",
    "        return self._convert_sp_mat_to_sp_tensor(norm_adj)\n",
    "\n",
    "    # scipy.sparse.coo_matrix -> torch.sparse.FloatTensorë¡œ ë°”ê¾¸ëŠ” ì—­í• \n",
    "    def _convert_sp_mat_to_sp_tensor(self, mat):\n",
    "        mat = mat.tocoo().astype(np.float32) # coo í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  íƒ€ì…ì„ float32ë¡œ ë³€í™˜\n",
    "        indices = torch.from_numpy(np.vstack((mat.row, mat.col))).long() # (row, col) ì¸ë±ìŠ¤ë¥¼ Pytorch tensorë¡œ ë³€í™˜\n",
    "        values = torch.from_numpy(mat.data) # ê° ì—£ì§€ì˜ ê°’(ê°€ì¤‘ì¹˜)ì„ tensorë¡œ ë³€í™˜\n",
    "        shape = torch.Size(mat.shape) # ì „ì²´ sparse tensorì˜ shape ê²°ì •\n",
    "        return torch.sparse_coo_tensor(indices, values, shape).to(self.user_embedding.weight.device) # sparse tensorë¡œ ìƒì„±í•˜ê³  ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "\n",
    "    # ìœ ì €/ì•„ì´í…œ ì´ˆê¸° ì„ë² ë”©ì„ ê·¸ë˜í”„ ì „íŒŒë¥¼ í†µí•´ ì—…ë°ì´íŠ¸í•˜ê³  í‰ê·  ì„ë² ë”© ë³€í™˜\n",
    "    def getEmbedding(self):\n",
    "        all_emb = torch.cat([self.user_embedding.weight, self.item_embedding.weight]) # ìœ ì €/ì•„ì´í…œ ì´ˆê¸° ì„ë² ë”© ì—°ê²° (Layer0)\n",
    "        embs = [all_emb] # ê° ë ˆì´ì–´ë³„ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        adj = self.norm_adj\n",
    "        \n",
    "        # LightGCN message passing : ê° ë ˆì´ì–´ë§ˆë‹¤ ì„ë² ë”© ì—…ë°ì´íŠ¸\n",
    "        for _ in range(self.num_layers):\n",
    "            all_emb = torch.sparse.mm(adj, all_emb)\n",
    "            embs.append(all_emb)\n",
    "        \n",
    "        embs = torch.stack(embs, dim=1) # ëª¨ë“  ë ˆì´ì–´ì˜ ì„ë² ë”©ì„ ìŒ“ê³ ,\n",
    "        light_out = torch.mean(embs, dim=1) # ë ˆì´ì–´ë³„ ì„ë² ë”© í‰ê· \n",
    "        user_emb, item_emb = light_out[:self.num_users], light_out[self.num_users:] # ìœ ì €/ì•„ì´í…œ ì„ë² ë”© ë¶„ë¦¬í•´ì„œ ë°˜í™˜\n",
    "        return user_emb, item_emb\n",
    "\n",
    "    # ëª¨ë“  ì•„ì´í…œì— ëŒ€í•œ í‰ì  ì˜ˆì¸¡ ì ìˆ˜ ë°˜í™˜ \n",
    "    def getUsersRating(self, users):\n",
    "        user_emb, item_emb = self.getEmbedding() # GCN ê¸°ë°˜ìœ¼ë¡œ ìœ ì €/ì•„ì´í…œ ì„ë² ë”© ì¶”ì¶œ\n",
    "        users_emb = user_emb[users] # ê° ìœ ì €/positive/negative ì•„ì´í…œì˜ GCN ì„ë² ë”© ì¶”ì¶œ\n",
    "        scores = torch.matmul(users_emb, item_emb.t()) # ìœ ì € ì„ë² ë”©ê³¼ ì „ì²´ ì•„ì´í…œ ì„ë² ë”© ê°„ ë‚´ì í•˜ì—¬ í‰ì  ì˜ˆì¸¡ ì ìˆ˜ ì¶”ì¶œ\n",
    "        return torch.sigmoid(scores) # Sigmoidë¥¼ í†µí•´ ì ìˆ˜ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "\n",
    "    # ìœ ì €, positive item, negative item ì„ë² ë”©ì„ ê°ê° ì¶”ì¶œ + ì´ˆê¸° ì„ë² ë”©ë„ ë°˜í™˜\n",
    "    def getEmbeddingTriple(self, users, pos_items, neg_items):\n",
    "        user_emb, item_emb = self.getEmbedding()\n",
    "        users_emb = user_emb[users]\n",
    "        pos_emb = item_emb[pos_items]\n",
    "        neg_emb = item_emb[neg_items]\n",
    "        \n",
    "        users_emb_0 = self.user_embedding(users)\n",
    "        pos_emb_0 = self.item_embedding(pos_items)\n",
    "        neg_emb_0 = self.item_embedding(neg_items)\n",
    "        \n",
    "        return users_emb, pos_emb, neg_emb, users_emb_0, pos_emb_0, neg_emb_0\n",
    "\n",
    "    # GCN ë ˆì´ì–´ë¥¼ ë°˜ë³µí•˜ë©´ì„œ ìœ ì €/ì•„ì´í…œì˜ ì„ë² ë”©ì„ ì—…ë°ì´íŠ¸í•˜ê³  ë§ˆì§€ë§‰ì— í‰ê· ì„ ë‚´ì„œ ìµœì¢… ì„ë² ë”©ì„ ì¶œë ¥í•˜ëŠ” ê²ƒ\n",
    "    def forward(self):\n",
    "        # ì´ˆê¸° ì„ë² ë”© ê°€ì ¸ì˜¤ê¸° (Layer 0)\n",
    "        emb = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)\n",
    "        all_embs = [emb]\n",
    "        \n",
    "        adj = self.norm_adj\n",
    "        \n",
    "        # ë©”ì‹œì§€ ì „ë‹¬ (Layer ìˆ˜ ë§Œí¼ ë°˜ë³µ)\n",
    "        for _ in range(self.num_layers):\n",
    "            emb = torch.sparse.mm(adj, emb)\n",
    "            all_embs.append(emb)\n",
    "        \n",
    "        # ë ˆì´ì–´ë³„ ì„ë² ë”© í‰ê· \n",
    "        final_emb = torch.stack(all_embs, dim=0).mean(0)\n",
    "        \n",
    "        # ìœ ì €/ì•„ì´í…œ ì„ë² ë”© ë¶„ë¦¬\n",
    "        user_emb, item_emb = final_emb[:self.num_users], final_emb[self.num_users:]\n",
    "        return user_emb, item_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR Loss\n",
    "\n",
    "$$L_{BPR}=-\\sum_{(u,i,j)}log\\;\\sigma(\\hat y_{ui}-\\hat y_{uj})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(model, users, pos_items, neg_items):\n",
    "    # GCN ê²°ê³¼ + ì´ˆê¸° ì„ë² ë”© ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°\n",
    "    users_emb, pos_emb, neg_emb, user_emb_0, pos_emb_0, neg_emb_0 = model.getEmbeddingTriple(users.long(), pos_items.long(), neg_items.long())\n",
    "\n",
    "    # BPR loss ê³„ì‚°\n",
    "    pos_scores = torch.sum(users_emb * pos_emb, dim=1)\n",
    "    neg_scores = torch.sum(users_emb * neg_emb, dim=1)\n",
    "    loss = torch.mean(F.softplus(neg_scores - pos_scores))\n",
    "\n",
    "    # ì´ˆê¸° ì„ë² ë”©ì—ë§Œ ì •ê·œí™” ì ìš© (ë…¼ë¬¸ê³¼ ë™ì¼)\n",
    "    reg_loss = config['reg_lambda'] * (user_emb_0.norm(2).pow(2) + pos_emb_0.norm(2).pow(2) + neg_emb_0.norm(2).pow(2)) / users.shape[0]\n",
    "\n",
    "    return loss + reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=config['patience'], delta=0.0, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None or current_score > self.best_score + self.delta:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í‰ê°€ ì§€í‘œ & í•¨ìˆ˜\n",
    "\n",
    "í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” Recall@20, Precision@20, NDCG@20 ìœ¼ë¡œ ì§„í–‰í•˜ì˜€ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall@K : ì •ë‹µ ì•„ì´í…œ ì¤‘ ìƒìœ„ Kê°œì— í¬í•¨ëœ ë¹„ìœ¨\n",
    "def recall_at_k(ranked_list, ground_truth, k):\n",
    "    return len(set(ranked_list[:k]) & set(ground_truth)) / len(set(ground_truth))\n",
    "\n",
    "# Precision@K : ìƒìœ„ Kê°œ ì¤‘ ì •ë‹µ ì•„ì´í…œì˜ ë¹„ìœ¨\n",
    "def precision_at_k(ranked_list, ground_truth, k):\n",
    "    return len(set(ranked_list[:k]) & set(ground_truth)) / k\n",
    "\n",
    "# NDCG@K : ì •ë‹µ ì•„ì´í…œì˜ ìˆœìœ„ë¥¼ ê³ ë ¤í•œ ì •ë°€ë„ ì§€í‘œ\n",
    "def ndcg_at_k(ranked_list, ground_truth, k):\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(ranked_list[:k]):\n",
    "        if item in ground_truth:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(ground_truth), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# ì „ì²´ ìœ ì €ì— ëŒ€í•´ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (ë°°ì¹˜ ë‹¨ìœ„)\n",
    "def evaluate_model(model, test_ground_truth, user_item_dict, k=20, batch_size=1024, silent=False, desc=\"Evaluating\"):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        user_emb, item_emb = model()\n",
    "        user_emb = user_emb.to(device)\n",
    "        item_emb = item_emb.to(device)\n",
    "\n",
    "    recall_list, precision_list, ndcg_list = [], [], []\n",
    "    test_users = list(test_ground_truth.keys())\n",
    "\n",
    "    for i in tqdm(range(0, len(test_users), batch_size), desc=desc):\n",
    "        batch_users = test_users[i:i+batch_size]\n",
    "        batch_user_emb = user_emb[batch_users]\n",
    "\n",
    "        for idx, user in enumerate(batch_users):\n",
    "            gt_items = test_ground_truth[user]\n",
    "            train_items = user_item_dict.get(user, set())\n",
    "            candidates = list((set(range(model.num_items)) - train_items) | set(gt_items))\n",
    "\n",
    "            scores = torch.matmul(batch_user_emb[idx], item_emb[candidates].T)\n",
    "            ranked_items = [candidates[i] for i in torch.topk(scores, k).indices.tolist()]\n",
    "\n",
    "            recall_list.append(recall_at_k(ranked_items, gt_items, k))\n",
    "            precision_list.append(precision_at_k(ranked_items, gt_items, k))\n",
    "            ndcg_list.append(ndcg_at_k(ranked_items, gt_items, k))\n",
    "\n",
    "    if not silent:\n",
    "        print(f\"Recall@{k}: {np.mean(recall_list):.4f}, Precision@{k}: {np.mean(precision_list):.4f}, NDCG@{k}: {np.mean(ndcg_list):.4f}\")\n",
    "\n",
    "    return np.mean(recall_list), np.mean(precision_list), np.mean(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í•™ìŠµ ë£¨í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ê°œì˜ ë°°ì—´ì„ ë™ì¼í•œ ìˆœì„œë¡œ ë¬´ì‘ìœ„ ì…”í”Œ\n",
    "def shuffle(*arrays):\n",
    "    if len(set(len(x) for x in arrays)) != 1:\n",
    "        raise ValueError(\"All arrays must have the same length\")\n",
    "    idx = np.random.permutation(len(arrays[0]))\n",
    "    return tuple(x[idx] for x in arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì €ë³„ (user, pos, neg) íŠ¸ë¦¬í”Œ ìƒ˜í”Œ ìƒì„±\n",
    "def sample_user_triplets(user_item_dict, all_items, users):\n",
    "    samples = []\n",
    "    for u in users:\n",
    "        if not user_item_dict[u]:\n",
    "            continue\n",
    "        pos = random.choice(list(user_item_dict[u]))\n",
    "        neg_pool = list(all_items - user_item_dict[u])\n",
    "        if not neg_pool:\n",
    "            continue\n",
    "        neg = random.choice(neg_pool)\n",
    "        samples.append((u, pos, neg))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°°ì¹˜ ë‹¨ìœ„ë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê·  loss ë°˜í™˜\n",
    "def train_one_epoch(model, optimizer, user_item_dict, all_items, batch_size, device):\n",
    "    model.train()\n",
    "    users = list(user_item_dict.keys())\n",
    "    random.shuffle(users)\n",
    "    samples = sample_user_triplets(user_item_dict, all_items, users)\n",
    "\n",
    "    users_tensor = torch.tensor([s[0] for s in samples], device=device)\n",
    "    pos_tensor = torch.tensor([s[1] for s in samples], device=device)\n",
    "    neg_tensor = torch.tensor([s[2] for s in samples], device=device)\n",
    "\n",
    "    users_tensor, pos_tensor, neg_tensor = shuffle(users_tensor, pos_tensor, neg_tensor)\n",
    "\n",
    "    total_loss = 0\n",
    "    num_batches = len(users_tensor) // batch_size + 1\n",
    "\n",
    "    for start in range(0, len(users_tensor), batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_users = users_tensor[start:end]\n",
    "        batch_pos = pos_tensor[start:end]\n",
    "        batch_neg = neg_tensor[start:end]\n",
    "\n",
    "        loss = bpr_loss(model, batch_users, batch_pos, batch_neg)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ í•™ìŠµ ê³¼ì •ì„ ì‹¤í–‰í•˜ê³ , TensorBoard ë¡œê·¸ ë° EarlyStopping í¬í•¨\n",
    "def train_lightgcn(model, interactions, optimizer, test_ground_truth, user_item_dict,\n",
    "                   epochs=config['epochs'], batch_size=config['batch_size'], k=config['eval_k'], patience=config['patience']):\n",
    "    writer = SummaryWriter()\n",
    "    topks = [k]\n",
    "\n",
    "    # interactionì„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì €-ì•„ì´í…œ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±\n",
    "    user_item_dict.clear()\n",
    "    for u, i in zip(interactions[0], interactions[1]):\n",
    "        user_item_dict[u.item()].add(i.item())\n",
    "\n",
    "    all_items = set(range(model.num_items))\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"[Epoch {epoch+1}] Training start...\")\n",
    "        avg_loss = train_one_epoch(model, optimizer, user_item_dict, all_items, batch_size, device)\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {avg_loss:.4f}\")\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "\n",
    "        # í‰ê°€ ë° ë¡œê¹…\n",
    "        recall_all = {}\n",
    "        for topk in topks:\n",
    "            recall, prec, ndcg = evaluate_model(model, test_ground_truth, user_item_dict, topk, silent=True)\n",
    "            writer.add_scalars(f\"Metrics@{topk}\", {\"Recall\": recall, \"Precision\": prec, \"NDCG\": ndcg}, epoch)\n",
    "            recall_all[topk] = recall\n",
    "\n",
    "        # EarlyStopping ì²´í¬\n",
    "        recall = recall_all[k]\n",
    "        early_stopping(recall)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training start...\n",
      "Epoch 1: Loss = 0.6922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [09:12<00:00, 10.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Training start...\n",
      "Epoch 2: Loss = 0.6698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [25:08<00:00, 29.00s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Training start...\n",
      "Epoch 3: Loss = 0.6134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [32:12<00:00, 37.15s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Training start...\n",
      "Epoch 4: Loss = 0.5537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [09:18<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Training start...\n",
      "Epoch 5: Loss = 0.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [09:36<00:00, 11.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Training start...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ í•™ìŠµ\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain_lightgcn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_interactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_ground_truth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_item_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# í‰ê°€ ì„±ëŠ¥ (K=20)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m evaluate_model(model, test_ground_truth, user_item_dict, k\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_k\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mtrain_lightgcn\u001b[0;34m(model, interactions, optimizer, test_ground_truth, user_item_dict, epochs, batch_size, k, patience)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Training start...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_item_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, avg_loss, epoch)\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, user_item_dict, all_items, batch_size, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m bpr_loss(model, batch_users, batch_pos, batch_neg)\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = LightGCN(num_users, num_items, embedding_dim=config['embedding_dim'], num_layers=config['num_layers'], user_item_pairs=train_interactions)\n",
    "\n",
    "\n",
    "# Optimizer ì„¤ì •\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "train_lightgcn(\n",
    "    model,\n",
    "    train_interactions,\n",
    "    optimizer,\n",
    "    test_ground_truth,\n",
    "    user_item_dict,\n",
    "    epochs=config['epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    k=config['eval_k'],\n",
    "    patience=config['patience']\n",
    ")\n",
    "\n",
    "# í‰ê°€ ì„±ëŠ¥ (K=20)\n",
    "evaluate_model(model, test_ground_truth, user_item_dict, k=config['eval_k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall@20: 0.0687, Precision@20: 0.0034, NDCG@20: 0.0260"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
